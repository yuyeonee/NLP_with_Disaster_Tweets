{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-17T12:04:34.559144Z","iopub.execute_input":"2023-09-17T12:04:34.559528Z","iopub.status.idle":"2023-09-17T12:04:34.600790Z","shell.execute_reply.started":"2023-09-17T12:04:34.559494Z","shell.execute_reply":"2023-09-17T12:04:34.599416Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/nlp-getting-started/sample_submission.csv\n/kaggle/input/nlp-getting-started/train.csv\n/kaggle/input/nlp-getting-started/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"#numpy, pandas, seaborn\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport nltk\n\n#nltk\nimport re\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\n\n#matplot\nimport matplotlib.pyplot as plt\n\n#Tfidf\nfrom sklearn.feature_extraction.text import TfidfVectorizer","metadata":{"execution":{"iopub.status.busy":"2023-09-17T12:18:24.117688Z","iopub.execute_input":"2023-09-17T12:18:24.118178Z","iopub.status.idle":"2023-09-17T12:18:24.126698Z","shell.execute_reply.started":"2023-09-17T12:18:24.118138Z","shell.execute_reply":"2023-09-17T12:18:24.125174Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"nltk.download('wordnet')\n!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/","metadata":{"execution":{"iopub.status.busy":"2023-09-17T12:19:20.809265Z","iopub.execute_input":"2023-09-17T12:19:20.809682Z","iopub.status.idle":"2023-09-17T12:19:41.544266Z","shell.execute_reply.started":"2023-09-17T12:19:20.809649Z","shell.execute_reply":"2023-09-17T12:19:41.541954Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"[nltk_data] Error loading wordnet: <urlopen error [Errno -3] Temporary\n[nltk_data]     failure in name resolution>\nArchive:  /usr/share/nltk_data/corpora/wordnet.zip\n   creating: /usr/share/nltk_data/corpora/wordnet/\n  inflating: /usr/share/nltk_data/corpora/wordnet/lexnames  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.verb  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.adv  \n  inflating: /usr/share/nltk_data/corpora/wordnet/adv.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.verb  \n  inflating: /usr/share/nltk_data/corpora/wordnet/cntlist.rev  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.adj  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.adj  \n  inflating: /usr/share/nltk_data/corpora/wordnet/LICENSE  \n  inflating: /usr/share/nltk_data/corpora/wordnet/citation.bib  \n  inflating: /usr/share/nltk_data/corpora/wordnet/noun.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/verb.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/README  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.sense  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.noun  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.adv  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.noun  \n  inflating: /usr/share/nltk_data/corpora/wordnet/adj.exc  \n","output_type":"stream"}]},{"cell_type":"code","source":"train = pd.read_csv(\n    '/kaggle/input/nlp-getting-started/train.csv', \n    usecols=['text', 'target'], \n    dtype={'text': str, 'target': np.int64}\n)\ntest = pd.read_csv(\n    '/kaggle/input/nlp-getting-started/test.csv',\n    usecols=['text', 'id'], \n    dtype={'text': str, 'target': np.int64}\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-17T12:17:41.614703Z","iopub.execute_input":"2023-09-17T12:17:41.615092Z","iopub.status.idle":"2023-09-17T12:17:41.653985Z","shell.execute_reply.started":"2023-09-17T12:17:41.615060Z","shell.execute_reply":"2023-09-17T12:17:41.651160Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"lemmatizer = WordNetLemmatizer()\ndef txt_preprocess(text):\n    text = re.sub(r\"\\n\",\"\",text)\n    text = text.lower()\n    text = re.sub(r\"\\d\",\"\",text)        #Remove digits\n    text = re.sub(r'@\\w+','',text) # Remove mentions\n    text = re.sub(r'[^\\w\\s]','',text) #Remove punctuation\n    text = re.sub(r'http\\S+|www.\\S+', '', text) #Remove http\n    text = re.sub(r'<.*?>', '', text) # Remove html tags\n    \n    text = word_tokenize(text)\n    text = [word for word in text if word not in stopwords.words('english')]\n    \n    text = [lemmatizer.lemmatize(word) for word in text]\n    return ' '.join(text)","metadata":{"execution":{"iopub.status.busy":"2023-09-17T12:20:08.281510Z","iopub.execute_input":"2023-09-17T12:20:08.282045Z","iopub.status.idle":"2023-09-17T12:20:25.662675Z","shell.execute_reply.started":"2023-09-17T12:20:08.282005Z","shell.execute_reply":"2023-09-17T12:20:25.660944Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"train['text'] = train['text'].apply(txt_preprocess)","metadata":{"execution":{"iopub.status.busy":"2023-09-17T12:20:42.358280Z","iopub.execute_input":"2023-09-17T12:20:42.358848Z","iopub.status.idle":"2023-09-17T12:20:52.503051Z","shell.execute_reply.started":"2023-09-17T12:20:42.358805Z","shell.execute_reply":"2023-09-17T12:20:52.500728Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"test['text'] = test['text'].apply(txt_preprocess)","metadata":{"execution":{"iopub.status.busy":"2023-09-17T12:20:55.335901Z","iopub.execute_input":"2023-09-17T12:20:55.336304Z","iopub.status.idle":"2023-09-17T12:21:01.107368Z","shell.execute_reply.started":"2023-09-17T12:20:55.336273Z","shell.execute_reply":"2023-09-17T12:21:01.105047Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"x_train = train['text']\ny_train = train['target'].values\nx_test = test['text']","metadata":{"execution":{"iopub.status.busy":"2023-09-17T12:21:21.299609Z","iopub.execute_input":"2023-09-17T12:21:21.300014Z","iopub.status.idle":"2023-09-17T12:21:21.307228Z","shell.execute_reply.started":"2023-09-17T12:21:21.299981Z","shell.execute_reply":"2023-09-17T12:21:21.305764Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.2, random_state = 42)\nx_train.shape, x_val.shape, y_train.shape, y_val.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-17T12:22:06.402600Z","iopub.execute_input":"2023-09-17T12:22:06.403581Z","iopub.status.idle":"2023-09-17T12:22:06.421948Z","shell.execute_reply.started":"2023-09-17T12:22:06.403526Z","shell.execute_reply":"2023-09-17T12:22:06.420282Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"((6090,), (1523,), (6090,), (1523,))"},"metadata":{}}]},{"cell_type":"code","source":"tfv = TfidfVectorizer(max_features = 2000)\ntfv_x_train = tfv.fit_transform(x_train).toarray()\ntfv_x_test = tfv.transform(x_test).toarray()\ntfv_x_val = tfv.transform(x_val).toarray()\ntfv_x_test.shape, tfv_x_train.shape, tfv_x_val.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-17T12:23:22.491063Z","iopub.execute_input":"2023-09-17T12:23:22.491511Z","iopub.status.idle":"2023-09-17T12:23:22.737722Z","shell.execute_reply.started":"2023-09-17T12:23:22.491474Z","shell.execute_reply":"2023-09-17T12:23:22.736608Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"((3263, 2000), (6090, 2000), (1523, 2000))"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}